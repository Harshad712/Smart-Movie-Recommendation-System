{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f59328ba-4be9-4b35-b880-b436c0f2e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4db05b8-6bbe-466f-b5f8-0b0748550eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   userId  movieId  rating            timestamp\n",
      "0       1        2     3.5  2005-04-02 23:53:47\n",
      "1       1       29     3.5  2005-04-02 23:31:16\n",
      "2       1       32     3.5  2005-04-02 23:33:39\n",
      "3       1       47     3.5  2005-04-02 23:32:07\n",
      "4       1       50     3.5  2005-04-02 23:29:40\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Movies & Ratings datasets\n",
    "movies = pd.read_csv('data/movie.csv')\n",
    "ratings = pd.read_csv('data/rating.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(movies.head())\n",
    "print(ratings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d888ecb-1e76-4e5e-a692-5dea788f6fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Columns:\n",
      " Index(['movieId', 'title', 'genres'], dtype='object')\n",
      "\n",
      "Ratings Columns:\n",
      " Index(['userId', 'movieId', 'rating', 'timestamp'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Movies Columns:\\n\", movies.columns)\n",
    "print(\"\\nRatings Columns:\\n\", ratings.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6639aa2a-86a1-4ab6-91c8-2160427a7368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(movies.isnull().sum())\n",
    "print(ratings.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2029e51-2be1-4571-87f4-d4a14d174e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.duplicated().sum()\n",
    "ratings.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e2ee4b-45f4-4b02-bd72-2e4d8bf76fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating\n",
      "0       1        2     3.5\n",
      "1       1       29     3.5\n",
      "2       1       32     3.5\n",
      "3       1       47     3.5\n",
      "4       1       50     3.5\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.drop(columns=['timestamp'])\n",
    "print(ratings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01a19f94-6508-4adf-b0d0-68ed3a4d2cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                title  \\\n",
      "0                    Toy Story (1995)   \n",
      "1                      Jumanji (1995)   \n",
      "2             Grumpier Old Men (1995)   \n",
      "3            Waiting to Exhale (1995)   \n",
      "4  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                              genres  \n",
      "0  [Adventure, Animation, Children, Comedy, Fantasy]  \n",
      "1                     [Adventure, Children, Fantasy]  \n",
      "2                                  [Comedy, Romance]  \n",
      "3                           [Comedy, Drama, Romance]  \n",
      "4                                           [Comedy]  \n"
     ]
    }
   ],
   "source": [
    "def convert_genres(genre_str):\n",
    "    return genre_str.split('|') if isinstance(genre_str, str) else []\n",
    "\n",
    "movies['genres'] = movies['genres'].apply(convert_genres)\n",
    "print(movies[['title', 'genres']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c18c94c-5251-484a-afea-26f19c580356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Users: 138493\n",
      "Unique Movies: 27262\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique Users:\", ratings['userId'].nunique())\n",
    "print(\"Unique Movies:\", movies['title'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "284c8ab6-d45e-4312-8f62-baba4d3a3095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Train Set: (12613686, 3), Test Set: (3153422, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load ratings from dataset\n",
    "ratings_df = movies_df[['userId', 'movieId', 'rating']]\n",
    "\n",
    "# Split into 80% train, 20% test\n",
    "train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"âœ… Train Set: {train_data.shape}, Test Set: {test_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dcaa1af-1108-494f-8417-465bfa51e546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Users: 52596\n"
     ]
    }
   ],
   "source": [
    "# Count how many times each user has rated a movie\n",
    "user_rating_counts = ratings['userId'].value_counts()\n",
    "\n",
    "# Keep only users who have rated 50+ movies\n",
    "active_users = user_rating_counts[user_rating_counts >= 100].index\n",
    "\n",
    "# Filter ratings for these active users\n",
    "filtered_ratings = ratings[ratings['userId'].isin(active_users)]\n",
    "\n",
    "print(\"Filtered Users:\", filtered_ratings['userId'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4f521f9-a018-4248-a2bb-64589a8d5177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Movies: 8546\n"
     ]
    }
   ],
   "source": [
    "# Count how many ratings each movie has\n",
    "movie_rating_counts = ratings['movieId'].value_counts()\n",
    "\n",
    "# Keep only movies that have 50+ ratings\n",
    "popular_movies = movie_rating_counts[movie_rating_counts >= 100].index\n",
    "\n",
    "# Filter ratings for these popular movies\n",
    "filtered_ratings = filtered_ratings[filtered_ratings['movieId'].isin(popular_movies)]\n",
    "\n",
    "print(\"Filtered Movies:\", filtered_ratings['movieId'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b4f3424-8725-4f62-9adc-b7bb02a89e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Matrix Shape: (52596, 8546)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Create a mapping of movieId to a sequential index\n",
    "movie_id_to_index = {movie_id: idx for idx, movie_id in enumerate(filtered_ratings['movieId'].unique())}\n",
    "user_id_to_index = {user_id: idx for idx, user_id in enumerate(filtered_ratings['userId'].unique())}\n",
    "\n",
    "# Convert userId and movieId to sequential indices\n",
    "filtered_ratings['user_idx'] = filtered_ratings['userId'].map(user_id_to_index)\n",
    "filtered_ratings['movie_idx'] = filtered_ratings['movieId'].map(movie_id_to_index)\n",
    "\n",
    "# Create sparse matrix\n",
    "sparse_matrix = csr_matrix(\n",
    "    (filtered_ratings['rating'], (filtered_ratings['user_idx'], filtered_ratings['movie_idx'])),\n",
    "    shape=(len(user_id_to_index), len(movie_id_to_index))\n",
    ")\n",
    "\n",
    "print(\"Sparse Matrix Shape:\", sparse_matrix.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb56b13-4fc7-4167-837a-7555fdc9bb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  normalized_rating\n",
      "0       1        2     3.5           0.666667\n",
      "1       1       29     3.5           0.666667\n",
      "2       1       32     3.5           0.666667\n",
      "3       1       47     3.5           0.666667\n",
      "4       1       50     3.5           0.666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Extract ratings as a NumPy array\n",
    "ratings_array = filtered_ratings['rating'].values.reshape(-1, 1)\n",
    "\n",
    "# Initialize the MinMaxScaler (scales values between 0 and 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Fit and transform ratings\n",
    "normalized_ratings = scaler.fit_transform(ratings_array)\n",
    "\n",
    "# Replace original ratings with normalized values\n",
    "filtered_ratings['normalized_rating'] = normalized_ratings.flatten()\n",
    "\n",
    "# Print updated dataset\n",
    "print(filtered_ratings[['userId', 'movieId', 'rating', 'normalized_rating']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf6891a0-7f2a-49de-99c4-041c709d8406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  user_idx  movie_idx  normalized_rating  \\\n",
      "0       1        2     3.5         0          0           0.666667   \n",
      "1       1       29     3.5         0          1           0.666667   \n",
      "2       1       32     3.5         0          2           0.666667   \n",
      "3       1       47     3.5         0          3           0.666667   \n",
      "4       1       50     3.5         0          4           0.666667   \n",
      "\n",
      "                                               title  \\\n",
      "0                                     Jumanji (1995)   \n",
      "1  City of Lost Children, The (CitÃ© des enfants p...   \n",
      "2          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
      "3                        Seven (a.k.a. Se7en) (1995)   \n",
      "4                         Usual Suspects, The (1995)   \n",
      "\n",
      "                                         genres  \n",
      "0                [Adventure, Children, Fantasy]  \n",
      "1  [Adventure, Drama, Fantasy, Mystery, Sci-Fi]  \n",
      "2                   [Mystery, Sci-Fi, Thriller]  \n",
      "3                           [Mystery, Thriller]  \n",
      "4                    [Crime, Mystery, Thriller]  \n"
     ]
    }
   ],
   "source": [
    "# Merge movies.csv and filtered_ratings.csv on 'movieId'\n",
    "movies_with_ratings = filtered_ratings.merge(movies[['movieId', 'title', 'genres']], on='movieId', how='left')\n",
    "\n",
    "# Display the merged dataset\n",
    "print(movies_with_ratings.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8411d8ff-0af6-49e3-8c69-98c4a572bddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset saved successfully!\n"
     ]
    }
   ],
   "source": [
    "movies_with_ratings.to_csv('data/movies_merged.csv', index=False)\n",
    "print(\"Merged dataset saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a47d938-33fc-4380-a79c-0ade90d7f0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import save_npz\n",
    "\n",
    "# Save sparse matrix in a compressed format\n",
    "save_npz('data/user_movie_sparse_matrix.npz', sparse_matrix)\n",
    "\n",
    "print(\"Sparse matrix saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b5801c0-e72a-4c45-ba1d-28aa244bd497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating  user_idx  movie_idx  normalized_rating  \\\n",
      "0       1        2     3.5         0          0           0.666667   \n",
      "1       1       29     3.5         0          1           0.666667   \n",
      "2       1       32     3.5         0          2           0.666667   \n",
      "3       1       47     3.5         0          3           0.666667   \n",
      "4       1       50     3.5         0          4           0.666667   \n",
      "\n",
      "                                               title  \\\n",
      "0                                     Jumanji (1995)   \n",
      "1  City of Lost Children, The (CitÃ© des enfants p...   \n",
      "2          Twelve Monkeys (a.k.a. 12 Monkeys) (1995)   \n",
      "3                        Seven (a.k.a. Se7en) (1995)   \n",
      "4                         Usual Suspects, The (1995)   \n",
      "\n",
      "                                              genres  \n",
      "0               ['Adventure', 'Children', 'Fantasy']  \n",
      "1  ['Adventure', 'Drama', 'Fantasy', 'Mystery', '...  \n",
      "2                  ['Mystery', 'Sci-Fi', 'Thriller']  \n",
      "3                            ['Mystery', 'Thriller']  \n",
      "4                   ['Crime', 'Mystery', 'Thriller']  \n"
     ]
    }
   ],
   "source": [
    "# Load merged movies dataset\n",
    "movies_df = pd.read_csv(\"data/movies_merged.csv\")\n",
    "\n",
    "# Show first few rows\n",
    "print(movies_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0ac62-520b-40d4-89c4-a25f74ca2079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc65fea6-7d2d-4eb1-b12f-05675b192ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Movie Sparse Matrix Shape: (52596, 8546)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Load sparse user-movie ratings matrix\n",
    "user_movie_sparse = load_npz(\"data/user_movie_sparse_matrix.npz\")\n",
    "\n",
    "\n",
    "# Convert to compressed sparse row format (CSR) for efficient computation\n",
    "user_movie_csr = csr_matrix(user_movie_sparse)\n",
    "\n",
    "print(\"User-Movie Sparse Matrix Shape:\", user_movie_csr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dce270b5-4702-4ba8-a919-9b897bdb5c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 52596 users.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Reduce dimensions using SVD for better efficiency\n",
    "svd = TruncatedSVD(n_components=100)  # Reduce to 100 latent features\n",
    "user_reduced = svd.fit_transform(user_movie_csr)\n",
    "\n",
    "# Create FAISS index\n",
    "d = user_reduced.shape[1]  # Feature dimensions (100 after SVD)\n",
    "index = faiss.IndexFlatIP(d)  # Inner Product similarity (cosine equivalent)\n",
    "index.add(user_reduced)  # Add user embeddings to FAISS index\n",
    "\n",
    "print(\"FAISS index created with\", index.ntotal, \"users.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "241344d8-1904-426c-8106-bafc91afc134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 15, 17, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies_user_based(user_id, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend movies based on similar users' preferences.\n",
    "    \"\"\"\n",
    "    query_vector = user_reduced[user_id].reshape(1, -1)  # Get user vector\n",
    "    distances, indices = index.search(query_vector, 6)  # Find 5 similar users\n",
    "\n",
    "    top_similar_users = indices.flatten()[1:]  # Exclude the user itself\n",
    "\n",
    "    # Get ratings from similar users\n",
    "    similar_users_ratings = user_movie_csr[top_similar_users].mean(axis=0)\n",
    "\n",
    "    # Convert to Pandas Series (FIX: Ensure it's 1D)\n",
    "    movie_recommendations = pd.Series(similar_users_ratings.A1)  \n",
    "\n",
    "    # Get top movie recommendations\n",
    "    return movie_recommendations.nlargest(num_recommendations).index.tolist()\n",
    "\n",
    "# Example: Get recommendations for user 1\n",
    "print(recommend_movies_user_based(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "748500b2-c32d-4ca0-8e9b-311c96cbaaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created for movies.\n"
     ]
    }
   ],
   "source": [
    "# Reduce dimensions for items (movies)\n",
    "item_reduced = svd.fit_transform(user_movie_csr.T)  # Transpose for movie-based filtering\n",
    "\n",
    "# Create FAISS index for item-item similarity\n",
    "index_item = faiss.IndexFlatIP(item_reduced.shape[1])\n",
    "index_item.add(item_reduced)\n",
    "\n",
    "print(\"FAISS index created for movies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7f30f22-1e62-4ae1-a909-2f80a4bf7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 2, 9, 571, 284]\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies_item_based(movie_id, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend similar movies based on ratings.\n",
    "    \"\"\"\n",
    "    query_vector = item_reduced[movie_id].reshape(1, -1)\n",
    "    distances, indices = index_item.search(query_vector, num_recommendations + 1)\n",
    "\n",
    "    return indices.flatten()[1:].tolist()  # Exclude the input movie\n",
    "\n",
    "# Example: Get similar movies for movie ID 1\n",
    "print(recommend_movies_item_based(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f64bf20f-b122-4c69-967a-2e9d7af00e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape (Genres): (15767108, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Fill NaN genres with an empty string\n",
    "movies_df['genres'] = movies_df['genres'].fillna('')\n",
    "\n",
    "# Convert genres into a TF-IDF matrix\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(movies_df['genres'])\n",
    "\n",
    "print(\"TF-IDF Matrix Shape (Genres):\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a5c7ca9-ebd6-43fa-a361-8fff842a1c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape (Dense): (15767108, 21)\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert sparse TF-IDF matrix to dense format (required for FAISS)\n",
    "tfidf_dense = tfidf_matrix.toarray().astype('float32')  # Convert to float32 for FAISS\n",
    "\n",
    "print(\"TF-IDF Matrix Shape (Dense):\", tfidf_dense.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3c5ca54-f86f-449b-86dd-d1bf70762193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created with 15767108 movies.\n"
     ]
    }
   ],
   "source": [
    "# Define FAISS index for similarity search\n",
    "d = tfidf_dense.shape[1]  # Number of features\n",
    "index = faiss.IndexFlatIP(d)  # Inner product similarity (equivalent to cosine)\n",
    "index.add(tfidf_dense)  # Add movie vectors to the index\n",
    "\n",
    "print(\"FAISS index created with\", index.ntotal, \"movies.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c917ea9f-a9ed-4a84-bd98-f70766cad556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from movie titles to indices\n",
    "# Strip spaces and remove special characters from titles\n",
    "movies_df['title'] = movies_df['title'].astype(str).str.strip()\n",
    "\n",
    "# Update the title_to_index mapping\n",
    "title_to_index = pd.Series(movies_df.index, index=movies_df['title']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "22b63d79-621d-45db-a53c-b41f2f4ea6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tarzan (1999)', 'Secret of NIMH The (1982)']\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies_content_faiss(title, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend movies based on FAISS genre similarity.\n",
    "    Removes duplicate recommendations.\n",
    "    \"\"\"\n",
    "    # Step 3.1: Check if title exists\n",
    "    if title not in title_to_index:\n",
    "        # Try finding a close match\n",
    "        matching_titles = [t for t in title_to_index.keys() if title.lower() in t.lower()]\n",
    "        if not matching_titles:\n",
    "            return f\"Movie '{title}' not found in dataset.\"\n",
    "        title = matching_titles[0]  # Use first close match\n",
    "    \n",
    "    # Step 3.2: Retrieve Movie Index\n",
    "    movie_idx = title_to_index[title]\n",
    "\n",
    "    # Step 3.3: Ensure Query Vector Shape Matches FAISS Index\n",
    "    query_vector = tfidf_dense[movie_idx].reshape(1, -1).astype('float32')  \n",
    "\n",
    "    # Step 3.4: Search for Top Similar Movies\n",
    "    distances, indices = index.search(query_vector, num_recommendations * 2)  # Fetch extra results to filter out duplicates\n",
    "\n",
    "    # Step 3.5: Convert indices to movie titles & Remove Duplicates\n",
    "    unique_titles = []\n",
    "    seen_titles = set()\n",
    "    \n",
    "    for idx in indices.flatten():\n",
    "        movie_title = movies_df['title'].iloc[idx]\n",
    "        if movie_title not in seen_titles and movie_title != title:  # Exclude original movie\n",
    "            unique_titles.append(movie_title)\n",
    "            seen_titles.add(movie_title)\n",
    "        \n",
    "        if len(unique_titles) == num_recommendations:  # Stop once we have enough unique movies\n",
    "            break\n",
    "\n",
    "    return unique_titles\n",
    "\n",
    "# Example: Get similar movies for \"Up (2009)\"\n",
    "print(recommend_movies_content_faiss(\"Up (2009)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ab399da9-9083-4ee7-b288-fa4c4c2663ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jumanji (1995)', 'City of Lost Children The (Cit des enfants perdus La) (1995)', 'Twelve Monkeys (aka 12 Monkeys) (1995)', 'Seven (aka Se7en) (1995)', 'Usual Suspects The (1995)']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define weights for the hybrid model\n",
    "ALPHA = 0.6  # Weight for Collaborative Filtering\n",
    "BETA = 1 - ALPHA  # Weight for Content-Based Filtering\n",
    "\n",
    "def recommend_movies_hybrid(user_id, title=\"\", num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Hybrid Recommendation System:\n",
    "    Combines User-Based Collaborative Filtering & Content-Based Filtering.\n",
    "    \n",
    "    Parameters:\n",
    "    - user_id: ID of the user for collaborative filtering\n",
    "    - title: Movie title for content-based filtering\n",
    "    - num_recommendations: Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "    - List of recommended movie titles\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Get User-Based Collaborative Filtering Recommendations\n",
    "    try:\n",
    "        similar_users = user_similarity_df[user_id].sort_values(ascending=False)[1:6]  # Top 5 similar users\n",
    "        similar_users_ratings = user_movie_sparse[similar_users.index].mean(axis=0)  # Get average rating\n",
    "        \n",
    "        # Convert to Pandas Series & normalize scores\n",
    "        collaborative_scores = pd.Series(similar_users_ratings.A1, index=movies_df.index).fillna(0)\n",
    "        collaborative_scores = (collaborative_scores - collaborative_scores.min()) / (collaborative_scores.max() - collaborative_scores.min())  # Normalize\n",
    "    except:\n",
    "        collaborative_scores = pd.Series(0, index=movies_df.index)  # If no collaborative data, set to 0\n",
    "\n",
    "    # Step 2: Get Content-Based Filtering Recommendations\n",
    "    \n",
    "    if title==\"\" :\n",
    "        content_scores = pd.Series(0, index=movies_df.index)  # If no content data, set to 0\n",
    "    else :   \n",
    "        content_similar_movies = recommend_movies_content_faiss(title, num_recommendations * 2)  # Get more to avoid duplicates\n",
    "        content_scores = pd.Series(1, index=[title_to_index[movie] for movie in content_similar_movies if movie in title_to_index])\n",
    "    \n",
    "\n",
    "    # Step 3: Merge Scores Using Weighted Hybrid Formula\n",
    "    hybrid_scores = ALPHA * collaborative_scores + BETA * content_scores\n",
    "\n",
    "    # Step 4: Get Top Movie Recommendations\n",
    "    top_movies = hybrid_scores.nlargest(num_recommendations).index\n",
    "    return movies_df['title'].iloc[top_movies].tolist()\n",
    "\n",
    "# Example: Get hybrid recommendations for user 1 & movie \"Up (2009)\"\n",
    "print(recommend_movies_hybrid(user_id=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b6e391bc-a080-492d-8dba-4f599bb605cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique user IDs from ratings dataset\n",
    "user_ids = sorted(movies_df['userId'].unique().tolist())  # Ensure sorted order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14592b5-da5f-4e2a-be49-b20de6c3ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  # For converting string lists into actual lists\n",
    "\n",
    "# Initialize an empty set to store unique genres\n",
    "all_genres = set()\n",
    "\n",
    "# Iterate over each row in the 'genres' column\n",
    "for genre_str in movies_df['genres'].dropna():\n",
    "    try:\n",
    "        genres = ast.literal_eval(genre_str)  # Convert string to list if needed\n",
    "    except (ValueError, SyntaxError):\n",
    "        genres = genre_str.split('|')  # If already formatted, split by \"|\"\n",
    "\n",
    "    all_genres.update(genres)  # Add individual genres to the set\n",
    "\n",
    "# Convert to sorted list & add \"All\" option\n",
    "unique_genre = [\"All\"] + sorted(all_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed1bffb7-1fb9-4162-93f5-3545be543888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated Mood-Genre Mapping for Sentiment Analysis\n",
    "mood_genre_mapping = {\n",
    "    \"Happy\": [\"Comedy\", \"Animation\", \"Musical\", \"Fantasy\", \"Children\"],\n",
    "    \"Sad\": [\"Drama\", \"War\", \"Film-Noir\"],\n",
    "    \"Excited\": [\"Action\", \"Adventure\", \"Thriller\", \"Sci-Fi\", \"Crime\"],\n",
    "    \"Neutral\": [\"Documentary\", \"Western\", \"IMAX\"],\n",
    "    \"Dark\": [\"Horror\", \"Mystery\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8a84a025-966d-43f4-a474-fad166fe60c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def gradio_recommend(user_id, movie_title, genre, user_mood, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Flexible Recommendation System supporting Mood, Genre, and Title-based filtering.\n",
    "    \"\"\"\n",
    "    # Get recommendations (Default: Hybrid Model)\n",
    "    if movie_title:\n",
    "        recommendations = recommend_movies_hybrid(user_id=int(user_id), title=movie_title, num_recommendations=num_recommendations)\n",
    "    else:\n",
    "        recommendations = recommend_movies_hybrid(user_id=int(user_id), num_recommendations=num_recommendations)  # No title provided\n",
    "\n",
    "    # Apply Genre Filtering (if selected)\n",
    "    if genre and genre != \"All\":\n",
    "        recommendations = [\n",
    "            movie for movie in recommendations \n",
    "            if genre in ast.literal_eval(movies_df[movies_df['title'] == movie]['genres'].values[0])\n",
    "        ]\n",
    "\n",
    "    # Apply Mood Filtering (if selected)\n",
    "    if user_mood in mood_genre_mapping:\n",
    "        mood_genres = set(mood_genre_mapping[user_mood])\n",
    "        recommendations = [\n",
    "            movie for movie in recommendations\n",
    "            if any(g in mood_genres for g in ast.literal_eval(movies_df[movies_df['title'] == movie]['genres'].values[0]))\n",
    "        ]\n",
    "    \n",
    "    return recommendations[:num_recommendations] if recommendations else [\"No recommendations found. Try different inputs.\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "14ae7f1d-4299-4edb-b671-49bd5ac89dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* Running on public URL: https://d0aa436725f0cb4f30.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d0aa436725f0cb4f30.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸŽ¬ Smart Movie Recommendation System (Flexible Mode)\")\n",
    "\n",
    "    user_id_dropdown = gr.Dropdown(choices=user_ids, label=\"Select User ID\")\n",
    "\n",
    "    # Optional Inputs\n",
    "    movie_title_input = gr.Textbox(label=\"Enter Movie Title \")\n",
    "    genre_dropdown = gr.Dropdown(choices=unique_genre, label=\"Select Genre (Optional)\")\n",
    "    mood_dropdown = gr.Dropdown(choices=[\"Neutral\", \"Happy\", \"Sad\", \"Excited\", \"Dark\"], label=\"Select Mood (Optional)\")\n",
    "\n",
    "    num_recommendations_input = gr.Slider(1, 10, step=1, value=5, label=\"Number of Recommendations\")\n",
    "\n",
    "    output = gr.List(label=\"Recommended Movies\")\n",
    "\n",
    "    recommend_button = gr.Button(\"Get Recommendations\")\n",
    "    recommend_button.click(gradio_recommend, \n",
    "                           inputs=[user_id_dropdown, movie_title_input, genre_dropdown, mood_dropdown, num_recommendations_input], \n",
    "                           outputs=output)\n",
    "\n",
    "demo.launch(share= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "34afe451-66f7-4f11-bdf6-d6346dd03c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test Users: 52596\n"
     ]
    }
   ],
   "source": [
    "# Extract test data from your dataset (actual user-movie interactions)\n",
    "test_users = test_data['userId'].unique()  # Users in the test set\n",
    "\n",
    "# Get actual movie preferences per user\n",
    "actual_movies_per_user = {\n",
    "    user: test_data[test_data['userId'] == user]['movieId'].tolist()\n",
    "    for user in test_users\n",
    "}\n",
    "\n",
    "print(f\"âœ… Test Users: {len(test_users)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "8a511304-02cc-4fa8-8f3c-db9621633502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function WeakSet.__init__.<locals>._remove at 0x000001EC358A0040>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\LENOVO\\anaconda3\\Lib\\_weakrefset.py\", line 40, in _remove\n",
      "    self = selfref()\n",
      "           ^^^^^^^^^\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[159], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m evaluate_model(test_users, actual_movies_per_user)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Evaluated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(evaluation_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m users!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[159], line 7\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(test_users, actual_movies_per_user, num_recommendations)\u001b[0m\n\u001b[0;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m test_users:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Generate recommendations using YOUR custom model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     recommended_movies \u001b[38;5;241m=\u001b[39m recommend_movies_hybrid(user_id\u001b[38;5;241m=\u001b[39muser_id, num_recommendations\u001b[38;5;241m=\u001b[39mnum_recommendations)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Store actual and predicted values\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     actual_movies \u001b[38;5;241m=\u001b[39m actual_movies_per_user[user_id]\n",
      "Cell \u001b[1;32mIn[157], line 45\u001b[0m, in \u001b[0;36mrecommend_movies_hybrid\u001b[1;34m(user_id, title, num_recommendations)\u001b[0m\n\u001b[0;32m     42\u001b[0m hybrid_scores \u001b[38;5;241m=\u001b[39m ALPHA \u001b[38;5;241m*\u001b[39m collaborative_scores \u001b[38;5;241m+\u001b[39m BETA \u001b[38;5;241m*\u001b[39m content_scores\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Step 4: Get Top Movie Recommendations\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m top_movies \u001b[38;5;241m=\u001b[39m hybrid_scores\u001b[38;5;241m.\u001b[39mnlargest(num_recommendations)\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m movies_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[top_movies]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4252\u001b[0m, in \u001b[0;36mSeries.nlargest\u001b[1;34m(self, n, keep)\u001b[0m\n\u001b[0;32m   4154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnlargest\u001b[39m(\n\u001b[0;32m   4155\u001b[0m     \u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, keep: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4156\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   4157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4158\u001b[0m \u001b[38;5;124;03m    Return the largest `n` elements.\u001b[39;00m\n\u001b[0;32m   4159\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4250\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[0;32m   4251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selectn\u001b[38;5;241m.\u001b[39mSelectNSeries(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39mn, keep\u001b[38;5;241m=\u001b[39mkeep)\u001b[38;5;241m.\u001b[39mnlargest()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\methods\\selectn.py:57\u001b[0m, in \u001b[0;36mSelectN.nlargest\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnlargest\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlargest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\methods\\selectn.py:102\u001b[0m, in \u001b[0;36mSelectNSeries.compute\u001b[1;34m(self, method)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[[]]\n\u001b[0;32m    101\u001b[0m dropped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m--> 102\u001b[0m nan_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mdrop(dropped\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# slow method\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:5356\u001b[0m, in \u001b[0;36mSeries.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5260\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5261\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5268\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5269\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5271\u001b[0m \u001b[38;5;124;03m    Return Series with specified index labels removed.\u001b[39;00m\n\u001b[0;32m   5272\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5354\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   5355\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5357\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5358\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5359\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5360\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5361\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5362\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5363\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5364\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4831\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4835\u001b[0m     is_tuple_labels \u001b[38;5;241m=\u001b[39m is_nested_list_like(labels) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, \u001b[38;5;28mtuple\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3878\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   3821\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_indexer\u001b[39m(\n\u001b[0;32m   3822\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3826\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mintp]:\n\u001b[0;32m   3828\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3829\u001b[0m \u001b[38;5;124;03m    Compute indexer and mask for new index given the current index.\u001b[39;00m\n\u001b[0;32m   3830\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3876\u001b[0m \u001b[38;5;124;03m    and ``x`` is marked by -1, as it is not in ``index``.\u001b[39;00m\n\u001b[0;32m   3877\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3878\u001b[0m     method \u001b[38;5;241m=\u001b[39m clean_reindex_fill_method(method)\n\u001b[0;32m   3879\u001b[0m     orig_target \u001b[38;5;241m=\u001b[39m target\n\u001b[0;32m   3880\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_listlike_indexer(target)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\missing.py:1073\u001b[0m, in \u001b[0;36mclean_reindex_fill_method\u001b[1;34m(method)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _fill_methods[method]\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m\"\u001b[39m: _pad_2d, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackfill\u001b[39m\u001b[38;5;124m\"\u001b[39m: _backfill_2d}[method]\n\u001b[1;32m-> 1073\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_reindex_fill_method\u001b[39m(method) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ReindexMethod \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Function to generate recommendations for each user\n",
    "def evaluate_model(test_users, actual_movies_per_user, num_recommendations=5):\n",
    "    results = []\n",
    "\n",
    "    for user_id in test_users:\n",
    "        # Generate recommendations using YOUR custom model\n",
    "        recommended_movies = recommend_movies_hybrid(user_id=user_id, num_recommendations=num_recommendations)\n",
    "\n",
    "        # Store actual and predicted values\n",
    "        actual_movies = actual_movies_per_user[user_id]\n",
    "\n",
    "        results.append((user_id, actual_movies, recommended_movies))\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_model(test_users, actual_movies_per_user)\n",
    "print(f\"âœ… Evaluated {len(evaluation_results)} users!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2353361-2b82-4624-8fd9-826098fc6e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa26606-6cab-43ba-aecf-6c4715cd3e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
